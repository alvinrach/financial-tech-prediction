{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "192d9d94-612b-448b-b6ee-1b39fbcdceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b69603-d184-4693-946a-9eb72fb84629",
   "metadata": {},
   "source": [
    "# Open Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cf8361-5f8d-4e17-a392-62fe5cdf3b96",
   "metadata": {},
   "source": [
    "Choose the feature only we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "282a48af-2ee2-4cd3-ac1e-4bee22c00f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287374/195087651.py:1: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('demographic.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('demographic.csv')\n",
    "df = df.drop('index', axis=1)\n",
    "\n",
    "df_bs = df[[\n",
    "    'flag_bad',\n",
    "    'de_age',\n",
    "    'de_gender',\n",
    "    'de_num_friends',\n",
    "    'de_monthly_salary',\n",
    "    'de_employment_type',\n",
    "    'de_employment_duration',\n",
    "    'de_education',\n",
    "    'de_marital_status',\n",
    "    'de_children',\n",
    "    'ph_call_log_stats',\n",
    "    'ph_total_contacts',\n",
    "    'de_date_joined',\n",
    "    'fb_last_updated_date',\n",
    "    'ph_app_list',\n",
    "    'fb_dob',\n",
    "    'fb_relation',\n",
    "    'fb_gender'\n",
    "]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879ff83f-7271-4c48-b1ba-2d9b98f73df5",
   "metadata": {},
   "source": [
    "Here we fill null values with unstated so the model can learn it also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58b262d0-460b-4431-bd9e-beffa83f1cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs.fb_gender = df_bs.fb_gender.fillna(\"unstated\")\n",
    "df_bs.fb_relation = df_bs.fb_relation.fillna('Unstated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d02e6f-de27-4e6a-8b0d-53a8412f1c2b",
   "metadata": {},
   "source": [
    "For fb relation, we also prevent high cardinality by assigning some category to other that is related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58ddbccc-0c80-4a45-b493-285d82c51791",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs['pending_relation'] = df_bs.fb_relation.str.contains('Pending')\n",
    "df_bs.fb_relation = df_bs.fb_relation.str.replace(' (Pending)', '')\n",
    "df_bs.fb_relation = df_bs.fb_relation.str.replace('In a civil union', 'Married')\n",
    "df_bs.fb_relation = df_bs.fb_relation.str.replace('In a domestic partnership', 'Married')\n",
    "df_bs.fb_relation = df_bs.fb_relation.str.replace('Separated', 'Divorced')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ff822c-de04-4b3c-8ff3-f073747fca7b",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c525a0b2-33a2-4ef9-8eda-dfee4421b6c1",
   "metadata": {},
   "source": [
    "We also create new feature: fb_age which is the difference between the date of birth in FB and date joined. For the EDA information that stated we need to find difference first, xgboost can handle it automatically and find pattern as long as we provide the root features (fb_age and the de_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d83e3bf-d001-4eb6-a5a7-4158e694519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs['fb_age'] = ((pd.to_datetime(df.de_date_joined, dayfirst=True) - pd.to_datetime(df.fb_dob))/pd.Timedelta(days=1))/365"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce420ff-ffd5-44d8-8fd5-c9e2eb5a710e",
   "metadata": {},
   "source": [
    "Then the interesting part. For app list, we extract several information about the user apps like gambling apps, clone, mod, finance risky, invest, adult and suspicious utility by using keywords. The idea behind finance risky and invest is my concern that they will use our bnpl to pay their margin or just fraudsters getting much money by more financial apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55861d46-80a5-4697-9d3d-6930c306158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    \"gambling\": ['casino', 'togel', 'prediksi', 'blackjack', 'jitu', 'mangosoft', 'zynga', 'gamble', 'dewa', 'jackpot', 'vegas', 'totolotto', 'slot', 'newflashbingo', 'luckywheel', 'roulette', 'poker', 'bingo', 'rummy', '777', '888'],\n",
    "    \"clone\": [\"clone\", \"dual\", \"parallel\", \"multi\" , \"whatscan\"],\n",
    "    \"modded\": [\"mod\", \"hack\", \"vip\", \"apk\", \"patched\", \"crack\", \"cheat\", \"unlocked\",\"premiumfree\",\"vipmod\",\"luckypatcher\"],\n",
    "    \"finance_risky\": ['loan', 'pinjam', 'tunai', 'uang', 'moneyapp', 'rupiah', 'cash', 'duit', 'kredit', 'modalku', 'julo', 'payday', 'cicil'],\n",
    "    \"invest\": ['stockbit', 'forex', 'mirae', 'coinbase', 'binance', 'saham'],\n",
    "    \"adult\": ['michat', 'tinder', 'bigolivegirlvideo', 'okcupid', \"live\", \"cam\", \"dating\", \"xxx\", \"sexy\", \"hot\", \"escort\", \"porn\"],\n",
    "    \"suspicious_utility\": ['fake', 'anony', \"booster\", \"cleaner\", \"locker\", \"battery\", \"optimizer\", \"antivirusfree\", \"speedup\", \"vpn\"],\n",
    "}\n",
    "# Create binary columns for each category\n",
    "for cat, keywords in categories.items():\n",
    "    df_bs[cat] = df_bs[\"ph_app_list\"].str.lower().apply(\n",
    "        lambda x: int(any(kw in x for kw in keywords))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbbbe23-7b34-4bfb-ab8e-87dc1adda15d",
   "metadata": {},
   "source": [
    "Then the last update days relative to the date joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "065e448e-52df-4c39-9697-79daa7c4b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = pd.to_datetime(df_bs.de_date_joined, dayfirst=True, errors=\"coerce\").dt.tz_localize(\"Asia/Jakarta\")\n",
    "updated = pd.to_datetime(df_bs.fb_last_updated_date, errors=\"coerce\")\n",
    "\n",
    "df_bs[\"date_diff\"] = ((joined - updated) / pd.Timedelta(days=1))\n",
    "del joined, updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7b53a68-3502-4291-847e-a3132c2c0099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_os(os_str):\n",
    "    if os_str is np.nan:\n",
    "        return None\n",
    "    \n",
    "    # --- Android ---\n",
    "    if os_str.startswith(\"Android\"):\n",
    "        match = re.search(r\"Android\\s(\\d+)(?:\\.(\\d+))?\", os_str)\n",
    "        if match:\n",
    "            major = int(match.group(1))\n",
    "            minor = match.group(2)\n",
    "\n",
    "            if major < 4:\n",
    "                return \"Android Legacy (less than 4)\"\n",
    "            elif major == 4:\n",
    "                if minor in [\"0\", \"1\", \"2\", \"3\"]:\n",
    "                    return \"Android 4 (Jelly Bean/ICS)\"\n",
    "                elif minor == \"4\":\n",
    "                    return \"Android 4.4 (KitKat)\"\n",
    "                else:\n",
    "                    return \"Android 4 (Jelly Bean/ICS)\"  # fallback\n",
    "            elif major == 5:\n",
    "                return \"Android 5 (Lollipop)\"\n",
    "            elif major == 6:\n",
    "                return \"Android 6 (Marshmallow)\"\n",
    "            elif major == 7:\n",
    "                return \"Android 7 (Nougat)\"\n",
    "            elif major >= 8:\n",
    "                return \"Android 8+ (Oreo & later)\"\n",
    "    \n",
    "    # --- iOS ---\n",
    "    if os_str.startswith(\"iOS\"):\n",
    "        match = re.search(r\"iOS\\s(\\d+)\", os_str)\n",
    "        if match:\n",
    "            major = int(match.group(1))\n",
    "            if major in [6, 7]:\n",
    "                return \"iOS 6-7\"\n",
    "            elif major in [8, 9]:\n",
    "                return \"iOS 8-9\"\n",
    "            elif major >= 10:\n",
    "                return \"iOS 10+\"\n",
    "    \n",
    "    return \"Other/Unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76570601-a4d0-441b-9e05-26e52a7e6bdf",
   "metadata": {},
   "source": [
    "Then other device info. Here i take 15% time of the project to really self labelling the data, thinking the features i got will improve it. The long explanation is at device.ipynb where I used external dataset (gsmarena) to map to the phone feature. This also to prevent high cardinality in production if we use all of the phone category although xgboost can handle that in research. Alas, this time taking big research of FE left me with lesser time to explore this rich dataset. There are more things that can be tried to explore in the cleaned dataset, should be.  \n",
    "\n",
    "Here we try to use phone price, whether its discontinued/cancelled, bucketed platform os (see normalize os function above), and sim number (back then dual sim was a new thing i believe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35e0062d-3399-44de-a48c-169f7a790e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_device = df[\"ph_other_device_info\"].apply(json.loads).apply(pd.Series)\n",
    "df_bs = pd.concat([df_bs, df_device], axis=1)\n",
    "del df_device\n",
    "\n",
    "df_mkt_gsm = pd.read_csv('marketing_gsm_clean.csv')\n",
    "df_mkt_gsm = df_mkt_gsm[[\n",
    "    'device_codename',\n",
    "    'brand',\n",
    "    'misc_price',\n",
    "    'platform_os',\n",
    "    'launch_status',\n",
    "    'body_sim',\n",
    "]]\n",
    "# Clean one error\n",
    "df_mkt_gsm.misc_price = df_mkt_gsm.misc_price.replace({'<c2><a3><e2><80><89>141.60 / $<e2><80><89>149.00':'About 180 EUR'})\n",
    "# Extract number only\n",
    "df_mkt_gsm.misc_price = df_mkt_gsm.misc_price.str.extract(r\"(\\d+)\")\n",
    "# Get os\n",
    "df_mkt_gsm.platform_os = df_mkt_gsm.platform_os.map(normalize_os)\n",
    "# Get continuation status\n",
    "df_mkt_gsm[\"discontinued\"] = df_mkt_gsm.launch_status.str.contains(\"Discontinued|Cancelled\", case=False)\n",
    "# Get sim number\n",
    "df_mkt_gsm.body_sim = df_mkt_gsm.body_sim.str.contains('Dual|Triple', case=False)\n",
    "df_bs = df_bs.merge(df_mkt_gsm, how='left', on=['device_codename', 'brand'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a96604-f8ae-49da-af8f-01eeafa67dec",
   "metadata": {},
   "source": [
    "Call log stats feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd0295ab-c69f-44c7-85e1-12a9fda54d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_call_log_stats = df[\"ph_call_log_stats\"].apply(lambda x: json.loads(x) if isinstance(x, str) else {}).apply(pd.Series)\n",
    "df_call_log_stats = df_call_log_stats.fillna(0)\n",
    "df_bs = pd.concat([df_bs, df_call_log_stats], axis=1)\n",
    "del df_call_log_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52a4ccf-cd4f-4995-8c2f-50420004406e",
   "metadata": {},
   "source": [
    "Drop the unused column and assign several things as str so it can be dummied as binary feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bd39f9e-9de1-4356-8b2c-faad45d0b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs = df_bs.drop(['brand', 'device_codename', 'ph_call_log_stats', 'de_date_joined', 'fb_last_updated_date', 'ph_app_list', 'fb_dob', 'launch_status'], axis=1)\n",
    "\n",
    "df_bs.de_employment_type = df_bs.de_employment_type.replace(4,3)\n",
    "\n",
    "df_bs.de_gender = df_bs.de_gender.astype(str)\n",
    "df_bs.de_employment_type = df_bs.de_employment_type.astype(str)\n",
    "df_bs.de_education = df_bs.de_education.astype(str)\n",
    "df_bs.de_marital_status = df_bs.de_marital_status.astype(str)\n",
    "df_bs.de_children = df_bs.de_children.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cd3b11-c0dc-4749-ae18-8a352cc67924",
   "metadata": {},
   "source": [
    "Prepare before modelling by splitting data into train and test, and use stratify y so the composition by flag bad is more or less the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdf6cfa1-7d1f-45c2-b5db-a6787ed2af71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs = pd.get_dummies(df_bs)\n",
    "\n",
    "y = df_bs.flag_bad\n",
    "X = df_bs.drop('flag_bad', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "del X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3a30bc-3bc4-4ad6-9402-36e9535e9e3c",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "818f6ea5-bb27-43cb-bbda-19f6b9c58854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2975730847523364"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(\n",
    "    # tree_method=\"hist\",  # use histogram, works for both CPU and GPU\n",
    "    # device=\"cuda:0\"      # instead of gpu_id\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "average_precision_score(y_test, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6174a59-ad63-409a-8a25-0e8109540c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4256, number of negative: 28561\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3895\n",
      "[LightGBM] [Info] Number of data points in the train set: 32817, number of used features: 112\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.129689 -> initscore=-1.903712\n",
      "[LightGBM] [Info] Start training from score -1.903712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3119062971766088"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "average_precision_score(y_test, y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c7b85d-64c6-404f-b1a0-34b7c00db67d",
   "metadata": {},
   "source": [
    "As its faster and higher in baseline result, i will promote this model to parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80a825cf-b5c0-4ace-aac6-8e8ee14f060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Handle imbalance\n",
    "# scale_pos_weight = (len(y_train) - sum(y_train)) / sum(y_train)\n",
    "\n",
    "# # Base model\n",
    "# model = LGBMClassifier(\n",
    "#     random_state=42,\n",
    "#     scale_pos_weight=scale_pos_weight\n",
    "# )\n",
    "\n",
    "# # Minimal parameter grid (tiny search space)\n",
    "# param_grid = {\n",
    "#     \"num_leaves\": [31, 63],         # small vs medium tree\n",
    "#     \"max_depth\": [-1, 10],          # unlimited vs moderate\n",
    "#     \"learning_rate\": [0.05, 0.1],   # slower vs faster\n",
    "#     \"n_estimators\": [100, 300]      # small vs medium rounds\n",
    "# }\n",
    "\n",
    "# # Grid search with 2-fold CV for speed\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=model,\n",
    "#     param_grid=param_grid,\n",
    "#     scoring='average_precision',\n",
    "#     cv=2,          # fast\n",
    "#     verbose=1,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# # Fit\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Best model\n",
    "# best_model = grid_search.best_estimator_\n",
    "# print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# # Evaluate\n",
    "# y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "# ap = average_precision_score(y_test, y_proba)\n",
    "# print(\"Average Precision Score on test:\", ap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790e2932-50a5-4c94-b478-e0b6546d1132",
   "metadata": {},
   "source": [
    "The choosen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fe238fd-981a-472f-9bb0-04e4f7a4067f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4256, number of negative: 28561\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3895\n",
      "[LightGBM] [Info] Number of data points in the train set: 32817, number of used features: 112\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.129689 -> initscore=-1.903712\n",
      "[LightGBM] [Info] Start training from score -1.903712\n",
      "Result: 0.31239447644517254\n"
     ]
    }
   ],
   "source": [
    "# Handle class imbalance\n",
    "scale_pos_weight = (len(y_train) - sum(y_train)) / sum(y_train)\n",
    "\n",
    "# Quick test model\n",
    "model = LGBMClassifier(\n",
    "    num_leaves=31,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=scale_pos_weight\n",
    ")\n",
    "\n",
    "# Fit\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "ap = average_precision_score(y_test, y_proba)\n",
    "print(\"Result:\", ap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df924d20-9c0d-430f-9f63-6fa7e041cbc4",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efd94b5-772a-4b0a-beb9-7d1266f3e709",
   "metadata": {},
   "source": [
    "We can set recall threshold around 80% to getting all the true positives more for a thumb rule. It can be adjusted also by discussion with management and credit risk team regarding the threshold and user flow each time, and if we have also other metric that measures directly to opportunity cost lost or potential gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d97455fc-606d-4d42-9086-044da536b69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold for recall ≈ 80%: 0.36\n",
      "Recall: 0.802, Precision: 0.206, F1: 0.328\n"
     ]
    }
   ],
   "source": [
    "target_recall = 0.8\n",
    "best_thresh = 0\n",
    "closest_diff = 1.0  # start with max difference\n",
    "\n",
    "thresholds = np.arange(0.0, 1.01, 0.01)\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred = (y_proba >= t).astype(int)\n",
    "    r = recall_score(y_test, y_pred)\n",
    "    diff = abs(r - target_recall)\n",
    "    if diff < closest_diff:\n",
    "        closest_diff = diff\n",
    "        best_thresh = t\n",
    "\n",
    "# Final predictions using this threshold\n",
    "y_pred_final = (y_proba >= best_thresh).astype(int)\n",
    "recall = recall_score(y_test, y_pred_final)\n",
    "precision = precision_score(y_test, y_pred_final)\n",
    "f1 = f1_score(y_test, y_pred_final)\n",
    "\n",
    "print(f\"Threshold for recall ≈ {target_recall*100:.0f}%: {best_thresh:.2f}\")\n",
    "print(f\"Recall: {recall:.3f}, Precision: {precision:.3f}, F1: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fff0ffc-3fc1-4f66-8956-ed75d21c8555",
   "metadata": {},
   "source": [
    "Out of all our test dataset, we reject 4136 people to get that 80% recall threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1eed70d5-c314-478f-bff4-3823993c8735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 8205 samples:\n",
      "Approved (predicted good): 4069\n",
      "Rejected (predicted bad): 4136\n"
     ]
    }
   ],
   "source": [
    "# Count approvals and rejections\n",
    "num_reject = y_pred_final.sum()          # predicted bad\n",
    "num_approve = len(y_pred_final) - num_reject  # predicted good\n",
    "\n",
    "print(f\"Out of {len(y_pred_final)} samples:\")\n",
    "print(f\"Approved (predicted good): {num_approve}\")\n",
    "print(f\"Rejected (predicted bad): {num_reject}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917c8bdb-9845-44ea-9e79-61dc5449318b",
   "metadata": {},
   "source": [
    "Wrapping those all in a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6d935d2-bc40-47d7-8e02-e0f4e5bfb644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_prediciton():\n",
    "    df = pd.read_csv('demographic.csv')\n",
    "    df = df.drop('index', axis=1)\n",
    "    \n",
    "    df_bs = df[[\n",
    "        'flag_bad',\n",
    "        'de_age',\n",
    "        'de_gender',\n",
    "        'de_num_friends',\n",
    "        'de_monthly_salary',\n",
    "        'de_employment_type',\n",
    "        'de_employment_duration',\n",
    "        'de_education',\n",
    "        'de_marital_status',\n",
    "        'de_children',\n",
    "        'ph_call_log_stats',\n",
    "        'ph_total_contacts',\n",
    "        'de_date_joined',\n",
    "        'fb_last_updated_date',\n",
    "        'ph_app_list',\n",
    "        'fb_dob',\n",
    "        'fb_relation',\n",
    "        'fb_gender'\n",
    "    ]].copy()\n",
    "\n",
    "    df_bs.fb_gender = df_bs.fb_gender.fillna(\"unstated\")\n",
    "    \n",
    "    df_bs.fb_relation = df_bs.fb_relation.fillna('Unstated')\n",
    "    df_bs['pending_relation'] = df_bs.fb_relation.str.contains('Pending')\n",
    "    df_bs.fb_relation = df_bs.fb_relation.str.replace(' (Pending)', '')\n",
    "    df_bs.fb_relation = df_bs.fb_relation.str.replace('In a civil union', 'Married')\n",
    "    df_bs.fb_relation = df_bs.fb_relation.str.replace('In a domestic partnership', 'Married')\n",
    "    df_bs.fb_relation = df_bs.fb_relation.str.replace('Separated', 'Divorced')\n",
    "\n",
    "    df_bs['fb_age'] = ((pd.to_datetime(df.de_date_joined, dayfirst=True) - pd.to_datetime(df.fb_dob))/pd.Timedelta(days=1))/365\n",
    "    categories = {\n",
    "        \"gambling\": ['casino', 'togel', 'prediksi', 'blackjack', 'jitu', 'mangosoft', 'zynga', 'gamble', 'dewa', 'jackpot', 'vegas', 'totolotto', 'slot', 'newflashbingo', 'luckywheel', 'roulette', 'poker', 'bingo', 'rummy', '777', '888'],\n",
    "        \"clone\": [\"clone\", \"dual\", \"parallel\", \"multi\" , \"whatscan\"],\n",
    "        \"modded\": [\"mod\", \"hack\", \"vip\", \"apk\", \"patched\", \"crack\", \"cheat\", \"unlocked\",\"premiumfree\",\"vipmod\",\"luckypatcher\"],\n",
    "        \"finance_risky\": ['loan', 'pinjam', 'tunai', 'uang', 'moneyapp', 'rupiah', 'cash', 'duit', 'kredit', 'modalku', 'julo', 'payday', 'cicil'],\n",
    "        \"invest\": ['stockbit', 'forex', 'mirae', 'coinbase', 'binance', 'saham'],\n",
    "        \"adult\": ['michat', 'tinder', 'bigolivegirlvideo', 'okcupid', \"live\", \"cam\", \"dating\", \"xxx\", \"sexy\", \"hot\", \"escort\", \"porn\"],\n",
    "        \"suspicious_utility\": ['fake', 'anony', \"booster\", \"cleaner\", \"locker\", \"battery\", \"optimizer\", \"antivirusfree\", \"speedup\", \"vpn\"],\n",
    "    }\n",
    "    \n",
    "    # Create binary columns for each category\n",
    "    for cat, keywords in categories.items():\n",
    "        df_bs[cat] = df_bs[\"ph_app_list\"].str.lower().apply(\n",
    "            lambda x: int(any(kw in x for kw in keywords))\n",
    "        )\n",
    "    \n",
    "    joined = pd.to_datetime(df_bs.de_date_joined, dayfirst=True, errors=\"coerce\").dt.tz_localize(\"Asia/Jakarta\")\n",
    "    updated = pd.to_datetime(df_bs.fb_last_updated_date, errors=\"coerce\")\n",
    "    \n",
    "    df_bs[\"date_diff\"] = ((joined - updated) / pd.Timedelta(days=1))\n",
    "    del joined, updated\n",
    "    \n",
    "    df_device = df[\"ph_other_device_info\"].apply(json.loads).apply(pd.Series)\n",
    "    df_bs = pd.concat([df_bs, df_device], axis=1)\n",
    "    del df_device\n",
    "\n",
    "    df_mkt_gsm = pd.read_csv('marketing_gsm_clean.csv')\n",
    "    df_mkt_gsm = df_mkt_gsm[[\n",
    "        'device_codename',\n",
    "        'brand',\n",
    "        'misc_price',\n",
    "        'platform_os',\n",
    "        'launch_status',\n",
    "        'body_sim',\n",
    "    ]]\n",
    "    df_mkt_gsm.misc_price = df_mkt_gsm.misc_price.replace({'<c2><a3><e2><80><89>141.60 / $<e2><80><89>149.00':'About 180 EUR'})\n",
    "    df_mkt_gsm.misc_price = df_mkt_gsm.misc_price.str.extract(r\"(\\d+)\")\n",
    "    df_mkt_gsm.platform_os = df_mkt_gsm.platform_os.map(normalize_os)\n",
    "    df_mkt_gsm[\"discontinued\"] = df_mkt_gsm.launch_status.str.contains(\"Discontinued|Cancelled\", case=False)\n",
    "    df_mkt_gsm.body_sim = df_mkt_gsm.body_sim.str.contains('Dual|Triple', case=False)\n",
    "    df_bs = df_bs.merge(df_mkt_gsm, how='left', on=['device_codename', 'brand'])\n",
    "\n",
    "    df_call_log_stats = df[\"ph_call_log_stats\"].apply(lambda x: json.loads(x) if isinstance(x, str) else {}).apply(pd.Series)\n",
    "    df_call_log_stats = df_call_log_stats.fillna(0)\n",
    "    df_bs = pd.concat([df_bs, df_call_log_stats], axis=1)\n",
    "    del df_call_log_stats\n",
    "    \n",
    "    df_bs = df_bs.drop(['brand', 'device_codename', 'ph_call_log_stats', 'de_date_joined', 'fb_last_updated_date', 'ph_app_list', 'fb_dob', 'launch_status'], axis=1)\n",
    "\n",
    "    df_bs.de_employment_type = df_bs.de_employment_type.replace(4,3)\n",
    "    \n",
    "    df_bs.de_gender = df_bs.de_gender.astype(str)\n",
    "    df_bs.de_employment_type = df_bs.de_employment_type.astype(str)\n",
    "    df_bs.de_education = df_bs.de_education.astype(str)\n",
    "    df_bs.de_marital_status = df_bs.de_marital_status.astype(str)\n",
    "    df_bs.de_children = df_bs.de_children.astype(str)\n",
    "    \n",
    "    df_bs = pd.get_dummies(df_bs)\n",
    "    \n",
    "    y = df_bs.flag_bad\n",
    "    X = df_bs.drop('flag_bad', axis=1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "    del X, y\n",
    "\n",
    "    scale_pos_weight = (len(y_train) - sum(y_train)) / sum(y_train)\n",
    "    model = LGBMClassifier(\n",
    "        num_leaves=31,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=100,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        scale_pos_weight = scale_pos_weight\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    del X_train, y_train\n",
    "    \n",
    "    # y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:,1]\n",
    "    del X_test\n",
    "\n",
    "    return {\n",
    "        \"avg_prrc\": average_precision_score(y_test, y_proba)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d249cab-cd15-4eb2-bd15-877179506cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287374/2249824592.py:2: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('demographic.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4256, number of negative: 28561\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3895\n",
      "[LightGBM] [Info] Number of data points in the train set: 32817, number of used features: 112\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.129689 -> initscore=-1.903712\n",
      "[LightGBM] [Info] Start training from score -1.903712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'avg_prrc': 0.31239447644517254}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_prediciton()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463a38e3-2d37-4e97-8f0b-1952aa277113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
